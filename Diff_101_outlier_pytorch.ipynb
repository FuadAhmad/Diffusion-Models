{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49fa4f7e-bb63-4227-82e9-8cfd5405bc8d",
   "metadata": {},
   "source": [
    "## utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99da545-6ca6-476d-bf57-d9ee0e6978df",
   "metadata": {},
   "source": [
    "## ddpm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2edac87-5459-4ea4-a646-bf3d6c05fad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_steps=10 #1000\n",
    "beta_start=1e-2 #4\n",
    "beta_end=0.2 #0.02\n",
    "img_size=256\n",
    "device=\"cpu\"\n",
    "\n",
    "def prepare_noise_schedule():\n",
    "    return torch.linspace(beta_start, beta_end, noise_steps)\n",
    "\n",
    "beta = prepare_noise_schedule().to(device)\n",
    "alpha = 1. - beta\n",
    "alpha_hat = torch.cumprod(alpha, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0627850a-2104-45eb-b4fe-21ec0db544bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0100, 0.0311, 0.0522, 0.0733, 0.0944, 0.1156, 0.1367, 0.1578, 0.1789,\n",
       "        0.2000])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de0f0603-369d-4693-ab46-a7d124b65935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9900, 0.9689, 0.9478, 0.9267, 0.9056, 0.8844, 0.8633, 0.8422, 0.8211,\n",
       "        0.8000])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "59d9d780-dfc1-48a9-b4f1-972fd21bc1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9900, 0.9592, 0.9091, 0.8424, 0.7629, 0.6747, 0.5825, 0.4906, 0.4028,\n",
       "        0.3223])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3284a155-0c4f-4adb-b736-42e793c97640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7004)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = 7\n",
    "torch.sqrt(alpha_hat[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "569b0264-f088-49eb-b739-7e36d42ee7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4., 5., 6.])\n",
      "tensor([2.0000, 2.2361, 2.4495])\n",
      "tensor([[[[2.0000]]],\n",
      "\n",
      "\n",
      "        [[[2.2361]]],\n",
      "\n",
      "\n",
      "        [[[2.4495]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a sample tensor\n",
    "alpha_hat = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "\n",
    "# Extract the slice at index 1\n",
    "alpha_hat_t = alpha_hat[1]  # Tensor of shape (3,)\n",
    "print(alpha_hat_t)\n",
    "# Calculate the square root\n",
    "sqrt_alpha_hat_t = torch.sqrt(alpha_hat_t)  # Tensor of shape (3,)\n",
    "print(sqrt_alpha_hat_t)\n",
    "# Expand the tensor to have additional dimensions\n",
    "expanded_sqrt_alpha_hat_t = sqrt_alpha_hat_t[:, None, None, None]  # Tensor of shape (3, 1, 1, 1)\n",
    "\n",
    "print(expanded_sqrt_alpha_hat_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f14ce2cd-8955-4885-bf07-e02e4c06f228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4495)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(expanded_sqrt_alpha_hat_t[2][0][0][0])\n",
    "alpha_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b9bc15d-97b1-4218-b572-8fe1d123ad6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "#from utils import *\n",
    "#from modules import UNet\n",
    "import logging\n",
    "from torch.utils.tensorboard import SummaryWriter #!pip install tensorboard\n",
    "\n",
    "logging.basicConfig(format=\"%(asctime)s - %(levelname)s: %(message)s\", level=logging.INFO, datefmt=\"%I:%M:%S\")\n",
    "\n",
    "\n",
    "class Diffusion:\n",
    "    def __init__(self, noise_steps=1000, beta_start=1e-4, beta_end=0.02, img_size=256, device=\"cuda\"):\n",
    "        self.noise_steps = noise_steps\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        self.img_size = img_size\n",
    "        self.device = device\n",
    "\n",
    "        self.beta = self.prepare_noise_schedule().to(device)\n",
    "        self.alpha = 1. - self.beta\n",
    "        self.alpha_hat = torch.cumprod(self.alpha, dim=0)\n",
    "\n",
    "    def prepare_noise_schedule(self):\n",
    "        return torch.linspace(self.beta_start, self.beta_end, self.noise_steps)\n",
    "\n",
    "    def noise_images(self, x, t):\n",
    "        sqrt_alpha_hat = torch.sqrt(self.alpha_hat[t])[:, None, None, None]\n",
    "        print(sqrt_alpha_hat[0])\n",
    "        sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alpha_hat[t])[:, None, None, None]\n",
    "        Ɛ = torch.randn_like(x)\n",
    "        return sqrt_alpha_hat * x + sqrt_one_minus_alpha_hat * Ɛ, Ɛ\n",
    "\n",
    "    def sample_timesteps(self, n):\n",
    "        return torch.randint(low=1, high=self.noise_steps, size=(n,))\n",
    "\n",
    "    def sample(self, model, n):\n",
    "        logging.info(f\"Sampling {n} new images....\")\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            x = torch.randn((n, 3, self.img_size, self.img_size)).to(self.device)\n",
    "            for i in tqdm(reversed(range(1, self.noise_steps)), position=0):\n",
    "                t = (torch.ones(n) * i).long().to(self.device)\n",
    "                predicted_noise = model(x, t)\n",
    "                alpha = self.alpha[t][:, None, None, None]\n",
    "                alpha_hat = self.alpha_hat[t][:, None, None, None]\n",
    "                beta = self.beta[t][:, None, None, None]\n",
    "                if i > 1:\n",
    "                    noise = torch.randn_like(x)\n",
    "                else:\n",
    "                    noise = torch.zeros_like(x)\n",
    "                x = 1 / torch.sqrt(alpha) * (x - ((1 - alpha) / (torch.sqrt(1 - alpha_hat))) * predicted_noise) + torch.sqrt(beta) * noise\n",
    "        model.train()\n",
    "        x = (x.clamp(-1, 1) + 1) / 2\n",
    "        x = (x * 255).type(torch.uint8)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d0b11e-2479-43e2-bcb7-0351d7adbf41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "651868a7-e694-4f89-bed8-0a55164183b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    setup_logging(args.run_name)\n",
    "    device = args.device\n",
    "    dataloader = get_data(args)\n",
    "    model = UNet().to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=args.lr)\n",
    "    mse = nn.MSELoss()\n",
    "    diffusion = Diffusion(img_size=args.image_size, device=device)\n",
    "    logger = SummaryWriter(os.path.join(\"runs\", args.run_name))\n",
    "    l = len(dataloader)\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        logging.info(f\"Starting epoch {epoch}:\")\n",
    "        pbar = tqdm(dataloader)\n",
    "        for i, (images, _) in enumerate(pbar):\n",
    "            images = images.to(device)\n",
    "            t = diffusion.sample_timesteps(images.shape[0]).to(device)\n",
    "            x_t, noise = diffusion.noise_images(images, t)\n",
    "            predicted_noise = model(x_t, t)\n",
    "            loss = mse(noise, predicted_noise)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.set_postfix(MSE=loss.item())\n",
    "            logger.add_scalar(\"MSE\", loss.item(), global_step=epoch * l + i)\n",
    "\n",
    "        sampled_images = diffusion.sample(model, n=images.shape[0])\n",
    "        save_images(sampled_images, os.path.join(\"results\", args.run_name, f\"{epoch}.jpg\"))\n",
    "        torch.save(model.state_dict(), os.path.join(\"models\", args.run_name, f\"ckpt.pt\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "94265bf1-0bba-49df-afd5-2a21ac6565b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    args.device = torch.device(\"mps\") if torch.backends.mps.is_available() else \"cpu\" #\"cuda\"\n",
    "    # ckpt = torch.load(\"./working/orig/ckpt.pt\")\n",
    "    # model.load_state_dict(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f43e900-9af1-4d3d-bd23-0a4f858e9c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    launch()\n",
    "    # device = \"cuda\"\n",
    "    # model = UNet().to(device)\n",
    "    # ckpt = torch.load(\"./working/orig/ckpt.pt\")\n",
    "    # model.load_state_dict(ckpt)\n",
    "    # diffusion = Diffusion(img_size=64, device=device)\n",
    "    # x = diffusion.sample(model, 8)\n",
    "    # print(x.shape)\n",
    "    # plt.figure(figsize=(32, 32))\n",
    "    # plt.imshow(torch.cat([\n",
    "    #     torch.cat([i for i in x.cpu()], dim=-1),\n",
    "    # ], dim=-2).permute(1, 2, 0).cpu())\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027c8666-cb05-4cc6-8e97-07ee12a90528",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
